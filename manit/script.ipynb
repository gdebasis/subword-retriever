{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/manitk/.pyterrier/corpora/msmarco_passage/corpus/collection-gpt3.5.tsv', '/Users/manitk/.pyterrier/corpora/msmarco_passage/corpus/collection-sbert.tsv', '/Users/manitk/.pyterrier/corpora/msmarco_passage/corpus/collection.tsv']\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "import tiktoken\n",
    "\n",
    "dataset = pt.datasets.get_dataset(\"msmarco_passage\")\n",
    "print(dataset.get_corpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTopFrequentTerms(index_ref):\n",
    "    lexicon = index_ref.getLexicon()\n",
    "    term_freqs = []\n",
    "    iterator = lexicon.iterator()\n",
    "    while iterator.hasNext():\n",
    "        entry = iterator.next()\n",
    "        term_freqs.append((entry.getKey(), entry.getValue().getFrequency()))\n",
    "    top_terms = sorted(term_freqs, key=lambda x: x[1], reverse=True)[:50]\n",
    "    for term, freq in top_terms:\n",
    "        print(f\"{term}: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_indexer = pt.IterDictIndexer(\"./wordindex\", meta={'docno': 20, 'text': 4096})\n",
    "indexref = iter_indexer.index(dataset.get_corpus_iter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 8841823\n",
      "Number of terms: 1170682\n",
      "Number of postings: 215238456\n",
      "Number of fields: 0\n",
      "Number of tokens: 288759529\n",
      "Field names: []\n",
      "Positions:   false\n",
      "\n",
      "1: 2354388\n",
      "can: 2275758\n",
      "2: 1854040\n",
      "will: 1318185\n",
      "3: 1286521\n",
      "year: 1132892\n",
      "time: 1018130\n",
      "mai: 956589\n",
      "state: 849629\n",
      "4: 827548\n",
      "dai: 793715\n",
      "new: 792746\n",
      "name: 780596\n",
      "5: 757367\n",
      "first: 706850\n",
      "includ: 703524\n",
      "like: 660114\n",
      "caus: 651638\n",
      "need: 598907\n",
      "number: 593676\n",
      "who: 585304\n",
      "peopl: 576899\n",
      "call: 572439\n",
      "work: 571835\n",
      "mean: 563717\n",
      "onli: 551496\n",
      "type: 551279\n",
      "water: 549419\n",
      "cost: 547188\n",
      "take: 546892\n",
      "10: 524506\n",
      "averag: 520107\n",
      "system: 512566\n",
      "form: 505577\n",
      "000: 489118\n",
      "unit: 486448\n",
      "part: 468220\n",
      "bodi: 467482\n",
      "6: 466800\n",
      "us: 465184\n",
      "help: 454774\n",
      "servic: 449359\n",
      "see: 446033\n",
      "cell: 444133\n",
      "blood: 442774\n",
      "hour: 441033\n",
      "area: 433671\n",
      "just: 424045\n",
      "gener: 421644\n",
      "person: 415976\n"
     ]
    }
   ],
   "source": [
    "INDEX_DIR = '/Users/manitk/Desktop/GIR/Pyterrier/combined/wordindex/data.properties'\n",
    "indexref = pt.IndexFactory.of(INDEX_DIR)\n",
    "print(indexref.getCollectionStatistics())\n",
    "printTopFrequentTerms(indexref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 8841823\n",
      "Number of terms: 1170682\n",
      "Number of postings: 215238456\n",
      "Number of fields: 0\n",
      "Number of tokens: 288759529\n",
      "Field names: []\n",
      "Positions:   false\n",
      "\n",
      "17:07:01.695 [main] WARN org.terrier.structures.BaseCompressingMetaIndex -- Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 1.9 GiB of memory would be required.\n",
      "    nDCG@10  AP(rel=2)  AP(rel=3)       map\n",
      "0  0.493627   0.292988   0.287098  0.358724\n",
      "1  0.492575   0.292548   0.285249  0.358072\n",
      "2  0.509225   0.316460   0.305664  0.400533\n"
     ]
    }
   ],
   "source": [
    "from pyterrier.measures import *\n",
    "\n",
    "WORD_INDEX_DIR = '/Users/manitk/Desktop/GIR/Pyterrier/combined/wordindex/data.properties'\n",
    "word_index_ref = pt.IndexFactory.of(WORD_INDEX_DIR)\n",
    "\n",
    "print(word_index_ref.getCollectionStatistics())\n",
    "\n",
    "bm25 = pt.terrier.Retriever(word_index_ref, wmodel=\"BM25\")\n",
    "tfidf = pt.terrier.Retriever(word_index_ref, wmodel=\"TF_IDF\")\n",
    "rm3 = tfidf >> pt.rewrite.RM3(word_index_ref) >> tfidf\n",
    "\n",
    "results = pt.Experiment([bm25, tfidf, rm3], dataset.get_topics('test-2020'), dataset.get_qrels('test-2020'), eval_metrics=[nDCG@10, AP(rel=2), AP(rel=3), 'map'],names=[\"bm25\",\"tfidf\",\"rm3\"])\n",
    "print (results[[\"nDCG@10\", \"AP(rel=2)\", \"AP(rel=3)\", \"map\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def tokenize_text(input_file, output_file, model=\"gpt-3.5-turbo\"):\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "    delimiters = {\",\", \";\", \".\", \"(\", \")\", \"{\", \"}\", \"$\", \"%\", \"!\", \"?\", \"'\", \"\\\"\"}\n",
    "\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        reader = csv.reader(infile, delimiter='\\t')\n",
    "        writer = csv.writer(outfile, delimiter='\\t')\n",
    "\n",
    "        for row in reader:\n",
    "            if len(row) < 2:\n",
    "                continue  # Skip malformed lines\n",
    "\n",
    "            doc_id, text = row[0], row[1].lower()\n",
    "            tokenized_text = enc.encode(text)\n",
    "            tokenized_str = \" \".join(\n",
    "                token for t in tokenized_text \n",
    "                if (token := enc.decode_single_token_bytes(t).decode(\"utf-8\", errors=\"ignore\")) not in delimiters\n",
    "            )\n",
    "\n",
    "            tokenized_str = tokenized_str.replace(\"'s\", \"\")\n",
    "            writer.writerow([doc_id, tokenized_str])\n",
    "\n",
    "\n",
    "input_file = \"/Users/manitk/.pyterrier/corpora/msmarco_passage/corpus/collection.tsv\"\n",
    "output_file = \"/Users/manitk/.pyterrier/corpora/msmarco_passage/corpus/collection-gpt3.5.tsv\"\n",
    "tokenize_text(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"/Users/manitk/.pyterrier/corpora/msmarco_passage/corpus/collection-gpt3.5.tsv\" \n",
    "\n",
    "def msmarco_generate(file):\n",
    "    with pt.io.autoopen(file, 'rt') as corpusfile:\n",
    "        for l in corpusfile:\n",
    "            docno, passage = l.split(\"\\t\")\n",
    "            yield {'docno' : docno, 'text' : passage}\n",
    "\n",
    "iter_indexer = pt.IterDictIndexer(\"./gpt3.5_index\", meta={'docno': 20, 'text': 4096})\n",
    "indexref = iter_indexer.index(msmarco_generate(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 8841823\n",
      "Number of terms: 22887\n",
      "Number of postings: 242159486\n",
      "Number of fields: 0\n",
      "Number of tokens: 327156239\n",
      "Field names: []\n",
      "Positions:   false\n",
      "\n",
      "1: 2701885\n",
      "can: 2327496\n",
      "2: 2246091\n",
      "3: 1650529\n",
      "will: 1377989\n",
      "4: 1181627\n",
      "5: 1152220\n",
      "year: 1137277\n",
      "time: 1032526\n",
      "mai: 977397\n",
      "0: 941649\n",
      "201: 882254\n",
      "state: 859577\n",
      "new: 838625\n",
      "dai: 816441\n",
      "6: 793353\n",
      "name: 788967\n",
      "first: 709681\n",
      "includ: 702955\n",
      "like: 672250\n",
      "7: 669892\n",
      "caus: 639821\n",
      "al: 630672\n",
      "8: 609805\n",
      "work: 602136\n",
      "need: 601552\n",
      "number: 595085\n",
      "who: 590327\n",
      "water: 588445\n",
      "call: 581941\n",
      "peopl: 579235\n",
      "mean: 565803\n",
      "10: 564405\n",
      "cost: 561528\n",
      "type: 555653\n",
      "onli: 552150\n",
      "er: 550440\n",
      "take: 548450\n",
      "ic: 538051\n",
      "form: 532631\n",
      "ag: 521044\n",
      "th: 519342\n",
      "averag: 519092\n",
      "system: 515962\n",
      "000: 510843\n",
      "ing: 509574\n",
      "us: 497358\n",
      "unit: 485987\n",
      "part: 483942\n",
      "bodi: 474181\n"
     ]
    }
   ],
   "source": [
    "INDEX_DIR = '/Users/manitk/Desktop/GIR/Pyterrier/combined/gpt3.5_index/data.properties'\n",
    "indexref = pt.IndexFactory.of(INDEX_DIR)\n",
    "print(indexref.getCollectionStatistics())\n",
    "printTopFrequentTerms(indexref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = pt.datasets.get_dataset(\"msmarco_passage\")\n",
    "queries = dataset.get_topics('test-2020')\n",
    "queries.to_csv('msmarco_passage_test2020_queries.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/Users/manitk/Desktop/GIR/Pyterrier/combined/msmarco_passage_test2020_queries.tsv\"\n",
    "output_file = \"/Users/manitk/Desktop/GIR/Pyterrier/combined/msmarco_passage_test2020_queries-gpt3.5.tsv\"\n",
    "tokenize_text(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:16:36.138 [main] WARN org.terrier.structures.BaseCompressingMetaIndex -- Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 2 GiB of memory would be required.\n",
      "    nDCG@10  AP(rel=2)  AP(rel=3)       map\n",
      "0  0.385532   0.218319   0.222926  0.262193\n",
      "1  0.383712   0.218054   0.222480  0.262095\n",
      "2  0.378872   0.226950   0.214434  0.279654\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query_file = \"/Users/manitk/Desktop/GIR/Pyterrier/combined/msmarco_passage_test2020_queries-gpt3.5.tsv\"\n",
    "queries = pd.read_csv(query_file, sep='\\t', names=[\"qid\", \"query\"], dtype={\"qid\": str, \"query\": str})\n",
    "\n",
    "dataset = pt.datasets.get_dataset(\"msmarco_passage\")\n",
    "\n",
    "index_dir = \"./gpt3.5_index\"\n",
    "index_ref = pt.IndexFactory.of(index_dir)\n",
    "\n",
    "bm25 = pt.terrier.Retriever(index_ref, wmodel=\"BM25\")\n",
    "tfidf = pt.terrier.Retriever(index_ref, wmodel=\"TF_IDF\")\n",
    "rm3 = tfidf >> pt.rewrite.RM3(index_ref) >> tfidf\n",
    "\n",
    "results = pt.Experiment(\n",
    "    [bm25, tfidf, rm3],\n",
    "    queries,\n",
    "    dataset.get_qrels(\"test-2020\"),\n",
    "    eval_metrics=[nDCG@10, AP(rel=2), AP(rel=3), 'map'],\n",
    "    names=[\"bm25\",\"tfidf\",\"rm3\"]\n",
    ")\n",
    "\n",
    "print (results[[\"nDCG@10\", \"AP(rel=2)\", \"AP(rel=3)\", \"map\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SBERT Tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "import csv\n",
    "\n",
    "def sbert_tokenize_text(input_file, output_file, model_name='all-MiniLM-L6-v2'):\n",
    "    tokenizer = SentenceTransformer(model_name).tokenizer\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        reader = csv.reader(infile, delimiter='\\t')\n",
    "        writer = csv.writer(outfile, delimiter='\\t')\n",
    "\n",
    "        for row in reader:\n",
    "            if len(row) < 2:\n",
    "                continue\n",
    "\n",
    "            doc_id, text = row[0], row[1].lower()\n",
    "            tokens = tokenizer.tokenize(text)\n",
    "            tokenized_str = ' '.join(tokens).replace(\"##\", \"\")  # Clean WordPiece tokens\n",
    "            writer.writerow([doc_id, tokenized_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/Users/manitk/.pyterrier/corpora/msmarco_passage/corpus/collection.tsv\"\n",
    "output_file = \"/Users/manitk/.pyterrier/corpora/msmarco_passage/corpus/collection-sbert.tsv\"\n",
    "sbert_tokenize_text(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msmarco_generate_debug(file):\n",
    "    with pt.io.autoopen(file, 'rt') as corpusfile:\n",
    "        for idx, l in enumerate(corpusfile):\n",
    "            try:\n",
    "                docno, passage = l.strip().split(\"\\t\")\n",
    "                yield {'docno': docno, 'text': passage}\n",
    "                if idx % 100000 == 0:\n",
    "                    print(f\"Processed {idx} lines...\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error at line {idx}: {e}\")\n",
    "\n",
    "iter_indexer = pt.IterDictIndexer(\"./sbert_index\", meta={'docno': 20, 'text': 4096})\n",
    "indexref = iter_indexer.index(msmarco_generate_debug(output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_file = \"/Users/manitk/Desktop/GIR/Pyterrier/combined/msmarco_passage_test2020_queries.tsv\"\n",
    "output_query_file = \"/Users/manitk/Desktop/GIR/Pyterrier/combined/msmarco_passage_test2020_queries-sbert.tsv\"\n",
    "sbert_tokenize_text(query_file, output_query_file)\n",
    "\n",
    "import pandas as pd\n",
    "queries = pd.read_csv(output_query_file, sep='\\t', names=[\"qid\", \"query\"], dtype={\"qid\": str, \"query\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:00:01.819 [main] WARN org.terrier.structures.BaseCompressingMetaIndex -- Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 1.9 GiB of memory would be required.\n",
      "    nDCG@10  AP(rel=2)  AP(rel=3)       map\n",
      "0  0.423232   0.248772   0.257547  0.301504\n",
      "1  0.423862   0.248465   0.257057  0.301395\n",
      "2  0.412610   0.254249   0.245134  0.315919\n"
     ]
    }
   ],
   "source": [
    "from pyterrier.measures import *\n",
    "\n",
    "index_ref = pt.IndexFactory.of(\"./sbert_index\")\n",
    "\n",
    "bm25 = pt.terrier.Retriever(index_ref, wmodel=\"BM25\")\n",
    "tfidf = pt.terrier.Retriever(index_ref, wmodel=\"TF_IDF\")\n",
    "rm3 = tfidf >> pt.rewrite.RM3(index_ref) >> tfidf\n",
    "\n",
    "results = pt.Experiment(\n",
    "    [bm25, tfidf, rm3],\n",
    "    queries,\n",
    "    pt.datasets.get_dataset(\"msmarco_passage\").get_qrels(\"test-2020\"),\n",
    "    eval_metrics=[nDCG@10, AP(rel=2), AP(rel=3), 'map'],\n",
    "    names=[\"bm25\",\"tfidf\",\"rm3\"]\n",
    ")\n",
    "\n",
    "print(results[[\"nDCG@10\", \"AP(rel=2)\", \"AP(rel=3)\", \"map\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 8841823\n",
      "Number of terms: 17342\n",
      "Number of postings: 241019754\n",
      "Number of fields: 0\n",
      "Number of tokens: 327396708\n",
      "Field names: []\n",
      "Positions:   false\n",
      "\n",
      "1: 2524226\n",
      "can: 2339173\n",
      "2: 2097508\n",
      "3: 1467168\n",
      "will: 1322182\n",
      "year: 1137122\n",
      "time: 1049965\n",
      "4: 1007399\n",
      "mai: 966819\n",
      "5: 924514\n",
      "state: 851971\n",
      "dai: 817762\n",
      "new: 803596\n",
      "name: 801659\n",
      "er: 761159\n",
      "first: 708062\n",
      "includ: 702137\n",
      "like: 667246\n",
      "6: 653340\n",
      "ing: 650554\n",
      "caus: 650279\n",
      "work: 632310\n",
      "need: 600000\n",
      "number: 594171\n",
      "water: 591679\n",
      "who: 590100\n",
      "call: 579297\n",
      "peopl: 576599\n",
      "type: 565722\n",
      "mean: 564591\n",
      "10: 561739\n",
      "take: 558961\n",
      "cost: 555901\n",
      "7: 552380\n",
      "onli: 551157\n",
      "0: 550760\n",
      "8: 548994\n",
      "form: 533125\n",
      "averag: 519558\n",
      "system: 515412\n",
      "000: 499228\n",
      "unit: 487837\n",
      "part: 483970\n",
      "ag: 482865\n",
      "us: 475225\n",
      "bodi: 474189\n",
      "help: 461917\n",
      "blood: 459969\n",
      "see: 458336\n",
      "cell: 456710\n"
     ]
    }
   ],
   "source": [
    "INDEX_DIR = '/Users/manitk/Desktop/GIR/Pyterrier/combined/sbert_index/data.properties'\n",
    "indexref = pt.IndexFactory.of(INDEX_DIR)\n",
    "print(indexref.getCollectionStatistics())\n",
    "printTopFrequentTerms(indexref)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
