{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1928c8-bb12-44f9-b0c6-0d1b0790831b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/debasis/devtools/jdk-11.0.10.jdk/Contents/Home/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/Users/debasis/devtools/jdk-11.0.10.jdk/Contents/Home/\"\n",
    "print(os.getenv(\"JAVA_HOME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc3eafe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "from transformers import AutoTokenizer\n",
    "from collections import Counter\n",
    "from pyterrier.measures import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27641636-6068-4f65-84b4-e7ae2a16b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTopFrequentTerms(index_ref):\n",
    "    # Access the lexicon\n",
    "    lexicon = index_ref.getLexicon()\n",
    "    \n",
    "    # Extract terms and their frequencies\n",
    "    term_freqs = []\n",
    "    iterator = lexicon.iterator()\n",
    "    while iterator.hasNext():\n",
    "        entry = iterator.next()\n",
    "        term_freqs.append((entry.getKey(), entry.getValue().getFrequency()))\n",
    "    \n",
    "    # Sort by frequency and get the top 50 terms\n",
    "    top_terms = sorted(term_freqs, key=lambda x: x[1], reverse=True)[:50]\n",
    "    \n",
    "    # Print results\n",
    "    for term, freq in top_terms:\n",
    "        print(f\"{term}: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f947572d-e2c4-4a15-b2cf-32ee8fcb1dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:32:21.001 [main] WARN org.terrier.structures.BaseCompressingMetaIndex -- Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 1.9 GiB of memory would be required.\n",
      "Number of documents: 8841823\n",
      "Number of terms: 1170682\n",
      "Number of postings: 215238456\n",
      "Number of fields: 0\n",
      "Number of tokens: 288759529\n",
      "Field names: []\n",
      "Positions:   false\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>AP(rel=2)</th>\n",
       "      <th>AP(rel=3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.478310</td>\n",
       "      <td>0.232189</td>\n",
       "      <td>0.163141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rm3</td>\n",
       "      <td>0.525136</td>\n",
       "      <td>0.258130</td>\n",
       "      <td>0.194894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name   nDCG@10  AP(rel=2)  AP(rel=3)\n",
       "0  tfidf  0.478310   0.232189   0.163141\n",
       "1    rm3  0.525136   0.258130   0.194894"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pt.get_dataset('irds:msmarco-passage/trec-dl-2019')\n",
    "\n",
    "WORD_INDEX_DIR=\"./wordindex\"\n",
    "word_index_ref = pt.IndexFactory.of(WORD_INDEX_DIR)\n",
    "\n",
    "print(word_index_ref.getCollectionStatistics().toString())\n",
    "\n",
    "tfidf = pt.terrier.Retriever(word_index_ref, wmodel=\"TF_IDF\", num_results=100)\n",
    "#tfidf_gpt = pt.terrier.Retriever(index_ref, wmodel=\"TF_IDF\", properties={\"termpipelines\" : \"\"}, num_results=100)  # No tokenization\n",
    "\n",
    "rm3 = tfidf >> pt.rewrite.RM3(word_index_ref) >> tfidf\n",
    "pt.Experiment([tfidf, rm3], dataset.get_topics(), dataset.get_qrels(), eval_metrics=[nDCG@10, AP(rel=2), AP(rel=3)],names=[\"tfidf\", \"rm3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "357f9a1e-b093-44db-a888-8ec33859b68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:33:19.883 [main] WARN org.terrier.structures.BaseCompressingMetaIndex -- Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 2 GiB of memory would be required.\n",
      "Number of documents: 8841823\n",
      "Number of terms: 22887\n",
      "Number of postings: 242159486\n",
      "Number of fields: 0\n",
      "Number of tokens: 327156239\n",
      "Field names: []\n",
      "Positions:   false\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>AP(rel=2)</th>\n",
       "      <th>AP(rel=3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf-gpt-tokens</td>\n",
       "      <td>0.421618</td>\n",
       "      <td>0.187597</td>\n",
       "      <td>0.148047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf-gpt-tokens-rm3-50,20</td>\n",
       "      <td>0.471735</td>\n",
       "      <td>0.204556</td>\n",
       "      <td>0.169798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf-gpt-tokens-rm3-10,10</td>\n",
       "      <td>0.473803</td>\n",
       "      <td>0.210617</td>\n",
       "      <td>0.165043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf-gpt-tokens-rm3-20,20</td>\n",
       "      <td>0.471898</td>\n",
       "      <td>0.208558</td>\n",
       "      <td>0.171299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name   nDCG@10  AP(rel=2)  AP(rel=3)\n",
       "0            tfidf-gpt-tokens  0.421618   0.187597   0.148047\n",
       "1  tfidf-gpt-tokens-rm3-50,20  0.471735   0.204556   0.169798\n",
       "2  tfidf-gpt-tokens-rm3-10,10  0.473803   0.210617   0.165043\n",
       "3  tfidf-gpt-tokens-rm3-20,20  0.471898   0.208558   0.171299"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Queries from File\n",
    "query_file = \"pass_2019.gpt-tok.queries\"  # Change to your actual query file\n",
    "queries = pd.read_csv(query_file, sep='\\t', names=[\"qid\", \"query\"], dtype={\"qid\": str, \"query\": str})\n",
    "\n",
    "# Load the Indexed Collection\n",
    "index_dir = \"./gpt_index\"  # Path to your indexed data\n",
    "index_ref = pt.IndexFactory.of(index_dir)\n",
    "\n",
    "print(index_ref.getCollectionStatistics().toString())\n",
    "\n",
    "tfidf_gpt = pt.terrier.Retriever(index_ref, wmodel=\"TF_IDF\", num_results=100)  # No tokenization\n",
    "rm3_gpttok_50_20 = tfidf_gpt >> pt.rewrite.stash_results(clear=False) >> pt.rewrite.RM3(index_ref, fb_terms=50, fb_docs=20) >> pt.rewrite.reset_results() >> tfidf_gpt\n",
    "rm3_gpttok_10_10 = tfidf_gpt >> pt.rewrite.RM3(index_ref, fb_terms=10, fb_docs=10) >> tfidf_gpt\n",
    "rm3_gpttok_20_20 = tfidf_gpt >> pt.rewrite.RM3(index_ref, fb_terms=20, fb_docs=20) >> tfidf_gpt\n",
    "\n",
    "pt.Experiment([tfidf_gpt, rm3_gpttok_50_20, rm3_gpttok_10_10, rm3_gpttok_20_20],\n",
    "              queries, dataset.get_qrels(), eval_metrics=[nDCG@10, AP(rel=2), AP(rel=3)],\n",
    "              names=[\"tfidf-gpt-tokens\", \"tfidf-gpt-tokens-rm3-50,20\",\n",
    "                     \"tfidf-gpt-tokens-rm3-10,10\", \"tfidf-gpt-tokens-rm3-20,20\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3c7b3d-95b8-48ca-8f98-dce53e6b2930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
