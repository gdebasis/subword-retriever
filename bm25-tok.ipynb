{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5c4cc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/debasis/devtools/jdk-11.0.10.jdk/Contents/Home/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/Users/debasis/devtools/jdk-11.0.10.jdk/Contents/Home/\"\n",
    "print(os.getenv(\"JAVA_HOME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0923aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "from transformers import AutoTokenizer\n",
    "from collections import Counter\n",
    "from pyterrier.measures import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b728ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTopFrequentTerms(index_ref):\n",
    "    # Access the lexicon\n",
    "    lexicon = index_ref.getLexicon()\n",
    "    \n",
    "    # Extract terms and their frequencies\n",
    "    term_freqs = []\n",
    "    iterator = lexicon.iterator()\n",
    "    while iterator.hasNext():\n",
    "        entry = iterator.next()\n",
    "        term_freqs.append((entry.getKey(), entry.getValue().getFrequency()))\n",
    "    \n",
    "    # Sort by frequency and get the top 50 terms\n",
    "    top_terms = sorted(term_freqs, key=lambda x: x[1], reverse=True)[:50]\n",
    "    \n",
    "    # Print results\n",
    "    for term, freq in top_terms:\n",
    "        print(f\"{term}: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bafb220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:21:26.306 [main] WARN org.terrier.structures.BaseCompressingMetaIndex -- Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 1.9 GiB of memory would be required.\n",
      "    nDCG@10  AP(rel=2)  AP(rel=3)\n",
      "0  0.478310   0.232189   0.163141\n",
      "1  0.525136   0.258130   0.194894\n"
     ]
    }
   ],
   "source": [
    "dataset = pt.get_dataset('irds:msmarco-passage/trec-dl-2019')\n",
    "\n",
    "WORD_INDEX_DIR=\"./wordindex\"\n",
    "word_index_ref = pt.IndexFactory.of(WORD_INDEX_DIR)\n",
    "\n",
    "#print(word_index_ref.getCollectionStatistics().toString())\n",
    "\n",
    "tfidf = pt.terrier.Retriever(word_index_ref, wmodel=\"TF_IDF\", num_results=100)\n",
    "#tfidf_gpt = pt.terrier.Retriever(index_ref, wmodel=\"TF_IDF\", properties={\"termpipelines\" : \"\"}, num_results=100)  # No tokenization\n",
    "\n",
    "rm3 = tfidf >> pt.rewrite.RM3(word_index_ref) >> tfidf\n",
    "results = pt.Experiment([tfidf, rm3], dataset.get_topics(), dataset.get_qrels(), eval_metrics=[nDCG@10, AP(rel=2), AP(rel=3)],names=[\"tfidf\", \"rm3\"])\n",
    "print (results[[\"nDCG@10\", \"AP(rel=2)\", \"AP(rel=3)\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "348849e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:18:10.825 [main] WARN org.terrier.structures.BaseCompressingMetaIndex -- Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 2 GiB of memory would be required.\n",
      "    nDCG@10  AP(rel=2)  AP(rel=3)\n",
      "0  0.421618   0.187597   0.148047\n",
      "1  0.473803   0.210617   0.165043\n"
     ]
    }
   ],
   "source": [
    "dataset = pt.get_dataset('irds:msmarco-passage/trec-dl-2019')\n",
    "\n",
    "# Load Queries from File\n",
    "query_file = \"trecdl/pass_2019.gpt-tok.queries\"  # Change to your actual query file\n",
    "queries = pd.read_csv(query_file, sep='\\t', names=[\"qid\", \"query\"], dtype={\"qid\": str, \"query\": str})\n",
    "\n",
    "# Load the Indexed Collection\n",
    "index_dir = \"./gpt_index\"  # Path to your indexed data\n",
    "index_ref = pt.IndexFactory.of(index_dir)\n",
    "\n",
    "#print(index_ref.getCollectionStatistics().toString())\n",
    "\n",
    "tfidf_gpt = pt.terrier.Retriever(index_ref, wmodel=\"TF_IDF\", num_results=100)  # No tokenization\n",
    "rm3_gpttok = tfidf_gpt >> pt.rewrite.RM3(index_ref, fb_terms=10, fb_docs=10) >> tfidf_gpt\n",
    "\n",
    "results = pt.Experiment([tfidf_gpt, rm3_gpttok],\n",
    "              queries, dataset.get_qrels(), eval_metrics=[nDCG@10, AP(rel=2), AP(rel=3)],\n",
    "              names=[\"tfidf-gpt-tokens\", \"tfidf-gpt-tokens-rm3\"])\n",
    "print (results[[\"nDCG@10\", \"AP(rel=2)\", \"AP(rel=3)\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b435da-cdf7-4d35-bf79-dfc16dad947f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
